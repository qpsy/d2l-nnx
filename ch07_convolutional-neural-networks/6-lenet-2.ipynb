{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8b0c18e",
   "metadata": {
    "origin_pos": 1
   },
   "source": [
    "# Convolutional Neural Networks (LeNet)\n",
    ":label:`sec_lenet`\n",
    "\n",
    "We now have all the ingredients required to assemble\n",
    "a fully-functional CNN.\n",
    "In our earlier encounter with image data, we applied\n",
    "a linear model with softmax regression (:numref:`sec_softmax_scratch`)\n",
    "and an MLP (:numref:`sec_mlp-implementation`)\n",
    "to pictures of clothing in the Fashion-MNIST dataset.\n",
    "To make such data amenable we first flattened each image from a $28\\times28$ matrix\n",
    "into a fixed-length $784$-dimensional vector,\n",
    "and thereafter processed them in fully connected layers.\n",
    "Now that we have a handle on convolutional layers,\n",
    "we can retain the spatial structure in our images.\n",
    "As an additional benefit of replacing fully connected layers with convolutional layers,\n",
    "we will enjoy more parsimonious models that require far fewer parameters.\n",
    "\n",
    "In this section, we will introduce *LeNet*,\n",
    "among the first published CNNs\n",
    "to capture wide attention for its performance on computer vision tasks.\n",
    "The model was introduced by (and named for) Yann LeCun,\n",
    "then a researcher at AT&T Bell Labs,\n",
    "for the purpose of recognizing handwritten digits in images :cite:`LeCun.Bottou.Bengio.ea.1998`.\n",
    "This work represented the culmination\n",
    "of a decade of research developing the technology;\n",
    "LeCun's team published the first study to successfully\n",
    "train CNNs via backpropagation :cite:`LeCun.Boser.Denker.ea.1989`.\n",
    "\n",
    "At the time LeNet achieved outstanding results\n",
    "matching the performance of support vector machines,\n",
    "then a dominant approach in supervised learning, achieving an error rate of less than 1% per digit.\n",
    "LeNet was eventually adapted to recognize digits\n",
    "for processing deposits in ATM machines.\n",
    "To this day, some ATMs still run the code\n",
    "that Yann LeCun and his colleague Leon Bottou wrote in the 1990s!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9aa2b764",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:21:38.051474Z",
     "iopub.status.busy": "2023-08-18T19:21:38.050648Z",
     "iopub.status.idle": "2023-08-18T19:21:45.367586Z",
     "shell.execute_reply": "2023-08-18T19:21:45.366637Z"
    },
    "origin_pos": 5,
    "tab": [
     "jax"
    ]
   },
   "outputs": [],
   "source": [
    "# from types import FunctionType\n",
    "\n",
    "# from absl import logging\n",
    "# from flax import linen as nn\n",
    "# from clu import metric_writers\n",
    "# from flax.training import train_state\n",
    "# import jax\n",
    "# import jax.numpy as jnp\n",
    "# import ml_collections\n",
    "# import numpy as np\n",
    "# import optax\n",
    "# import tensorflow_datasets as tfds\n",
    "\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "import optax\n",
    "from flax import nnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2b17de",
   "metadata": {
    "origin_pos": 6
   },
   "source": [
    "## LeNet\n",
    "\n",
    "At a high level, (**LeNet (LeNet-5) consists of two parts:\n",
    "(i) a convolutional encoder consisting of two convolutional layers; and\n",
    "(ii) a dense block consisting of three fully connected layers**).\n",
    "The architecture is summarized in :numref:`img_lenet`.\n",
    "\n",
    "![Data flow in LeNet. The input is a handwritten digit, the output is a probability over 10 possible outcomes.](../img/lenet.svg)\n",
    ":label:`img_lenet`\n",
    "\n",
    "The basic units in each convolutional block\n",
    "are a convolutional layer, a sigmoid activation function,\n",
    "and a subsequent average pooling operation.\n",
    "Note that while ReLUs and max-pooling work better,\n",
    "they had not yet been discovered.\n",
    "Each convolutional layer uses a $5\\times 5$ kernel\n",
    "and a sigmoid activation function.\n",
    "These layers map spatially arranged inputs\n",
    "to a number of two-dimensional feature maps, typically\n",
    "increasing the number of channels.\n",
    "The first convolutional layer has 6 output channels,\n",
    "while the second has 16.\n",
    "Each $2\\times2$ pooling operation (stride 2)\n",
    "reduces dimensionality by a factor of $4$ via spatial downsampling.\n",
    "The convolutional block emits an output with shape given by\n",
    "(batch size, number of channel, height, width).\n",
    "\n",
    "In order to pass output from the convolutional block\n",
    "to the dense block,\n",
    "we must flatten each example in the minibatch.\n",
    "In other words, we take this four-dimensional input and transform it\n",
    "into the two-dimensional input expected by fully connected layers:\n",
    "as a reminder, the two-dimensional representation that we desire uses the first dimension to index examples in the minibatch\n",
    "and the second to give the flat vector representation of each example.\n",
    "LeNet's dense block has three fully connected layers,\n",
    "with 120, 84, and 10 outputs, respectively.\n",
    "Because we are still performing classification,\n",
    "the 10-dimensional output layer corresponds\n",
    "to the number of possible output classes.\n",
    "\n",
    "While getting to the point where you truly understand\n",
    "what is going on inside LeNet may have taken a bit of work,\n",
    "we hope that the following code snippet will convince you\n",
    "that implementing such models with modern deep learning frameworks\n",
    "is remarkably simple.\n",
    "We need only to instantiate a `Sequential` block\n",
    "and chain together the appropriate layers,\n",
    "using Xavier initialization as\n",
    "introduced in :numref:`subsec_xavier`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fdd0956",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nnx.Module):  #@save\n",
    "  \"\"\"The LeNet-5 model.\"\"\"\n",
    "  \n",
    "  def __init__(self, in_channels: int, num_classes: int, *, rngs: nnx.Rngs):\n",
    "    self.kernel_init = nnx.initializers.xavier_uniform\n",
    "    self.conv1 = nnx.Conv(in_features=in_channels, out_features=6, \n",
    "                          kernel_size=(5, 5), padding='SAME', \n",
    "                          kernel_init=self.kernel_init(), rngs=rngs)\n",
    "    self.conv2 = nnx.Conv(in_features=6, out_features=16, \n",
    "                          kernel_size=(5, 5), padding='VALID',\n",
    "                          kernel_init=self.kernel_init(), rngs=rngs)\n",
    "    self.avg_pool = partial(nnx.avg_pool, window_shape=(2, 2), strides=(2, 2))\n",
    "    self.linear1 = nnx.Linear(400, 120, kernel_init=self.kernel_init(), rngs=rngs)\n",
    "    self.linear2 = nnx.Linear(120, 84, kernel_init=self.kernel_init(), rngs=rngs)\n",
    "    self.linear3 = nnx.Linear(84, num_classes, kernel_init=self.kernel_init(), rngs=rngs)\n",
    "    \n",
    "  def __call__(self, x):\n",
    "    x = self.avg_pool(nnx.sigmoid(self.conv1(x)))\n",
    "    x = self.avg_pool(nnx.sigmoid(self.conv2(x)))\n",
    "    x = x.reshape(x.shape[0], -1)  # flatten\n",
    "    x = nnx.sigmoid(self.linear1(x))\n",
    "    x = nnx.sigmoid(self.linear2(x))\n",
    "    return self.linear3(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4522ac",
   "metadata": {
    "origin_pos": 10
   },
   "source": [
    "We have taken some liberty in the reproduction of LeNet insofar as we have replaced the Gaussian activation layer by\n",
    "a softmax layer. This greatly simplifies the implementation, not least due to the\n",
    "fact that the Gaussian decoder is rarely used nowadays. Other than that, this network matches\n",
    "the original LeNet-5 architecture.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4ee4b1",
   "metadata": {
    "origin_pos": 12,
    "tab": [
     "jax"
    ]
   },
   "source": [
    "Let's see what happens inside the network. By passing a\n",
    "single-channel (black and white)\n",
    "$28 \\times 28$ image through the network\n",
    "and printing the output shape at each layer,\n",
    "we can [**inspect the model**] to ensure\n",
    "that its operations line up with\n",
    "what we expect from :numref:`img_lenet_vert`.\n",
    "Flax provides `nn.tabulate`, a nifty method to summarise the layers and\n",
    "parameters in our network. Here we use the `bind` method to create a bounded model.\n",
    "The variables are now bound to the `d2l.Module` class, i.e., this bounded model\n",
    "becomes a stateful object which can then be used to access the `Sequential`\n",
    "object attribute `net` and the `layers` within. Note that the `bind` method should\n",
    "only be used for interactive experimentation, and is not a direct\n",
    "replacement for the `apply` method.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbac2a3",
   "metadata": {
    "origin_pos": 13
   },
   "source": [
    "![Compressed notation for LeNet-5.](../img/lenet-vert.svg)\n",
    ":label:`img_lenet_vert`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "500717cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet(in_channels=1, num_classes=10, rngs=nnx.Rngs(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d734d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet(\n",
       "  kernel_init=<function glorot_uniform at 0x12f502fc0>,\n",
       "  conv1=Conv(\n",
       "    kernel_shape=(5, 5, 1, 6),\n",
       "    kernel=Param(\n",
       "      value=Array(shape=(5, 5, 1, 6), dtype=float32)\n",
       "    ),\n",
       "    bias=Param(\n",
       "      value=Array(shape=(6,), dtype=float32)\n",
       "    ),\n",
       "    in_features=1,\n",
       "    out_features=6,\n",
       "    kernel_size=(5, 5),\n",
       "    strides=1,\n",
       "    padding='SAME',\n",
       "    input_dilation=1,\n",
       "    kernel_dilation=1,\n",
       "    feature_group_count=1,\n",
       "    use_bias=True,\n",
       "    mask=None,\n",
       "    dtype=None,\n",
       "    param_dtype=<class 'jax.numpy.float32'>,\n",
       "    precision=None,\n",
       "    kernel_init=<function variance_scaling.<locals>.init at 0x152dc1e40>,\n",
       "    bias_init=<function zeros at 0x12f47d300>,\n",
       "    conv_general_dilated=<function conv_general_dilated at 0x11f714860>\n",
       "  ),\n",
       "  conv2=Conv(\n",
       "    kernel_shape=(5, 5, 6, 16),\n",
       "    kernel=Param(\n",
       "      value=Array(shape=(5, 5, 6, 16), dtype=float32)\n",
       "    ),\n",
       "    bias=Param(\n",
       "      value=Array(shape=(16,), dtype=float32)\n",
       "    ),\n",
       "    in_features=6,\n",
       "    out_features=16,\n",
       "    kernel_size=(5, 5),\n",
       "    strides=1,\n",
       "    padding='VALID',\n",
       "    input_dilation=1,\n",
       "    kernel_dilation=1,\n",
       "    feature_group_count=1,\n",
       "    use_bias=True,\n",
       "    mask=None,\n",
       "    dtype=None,\n",
       "    param_dtype=<class 'jax.numpy.float32'>,\n",
       "    precision=None,\n",
       "    kernel_init=<function variance_scaling.<locals>.init at 0x152dc0900>,\n",
       "    bias_init=<function zeros at 0x12f47d300>,\n",
       "    conv_general_dilated=<function conv_general_dilated at 0x11f714860>\n",
       "  ),\n",
       "  avg_pool=functools.partial(<function avg_pool at 0x12f6d0e00>, window_shape=(2, 2), strides=(2, 2)),\n",
       "  linear1=Linear(\n",
       "    kernel=Param(\n",
       "      value=Array(shape=(400, 120), dtype=float32)\n",
       "    ),\n",
       "    bias=Param(\n",
       "      value=Array(shape=(120,), dtype=float32)\n",
       "    ),\n",
       "    in_features=400,\n",
       "    out_features=120,\n",
       "    use_bias=True,\n",
       "    dtype=None,\n",
       "    param_dtype=<class 'jax.numpy.float32'>,\n",
       "    precision=None,\n",
       "    kernel_init=<function variance_scaling.<locals>.init at 0x15564db20>,\n",
       "    bias_init=<function zeros at 0x12f47d300>,\n",
       "    dot_general=<function dot_general at 0x11f6afc40>\n",
       "  ),\n",
       "  linear2=Linear(\n",
       "    kernel=Param(\n",
       "      value=Array(shape=(120, 84), dtype=float32)\n",
       "    ),\n",
       "    bias=Param(\n",
       "      value=Array(shape=(84,), dtype=float32)\n",
       "    ),\n",
       "    in_features=120,\n",
       "    out_features=84,\n",
       "    use_bias=True,\n",
       "    dtype=None,\n",
       "    param_dtype=<class 'jax.numpy.float32'>,\n",
       "    precision=None,\n",
       "    kernel_init=<function variance_scaling.<locals>.init at 0x152334e00>,\n",
       "    bias_init=<function zeros at 0x12f47d300>,\n",
       "    dot_general=<function dot_general at 0x11f6afc40>\n",
       "  ),\n",
       "  linear3=Linear(\n",
       "    kernel=Param(\n",
       "      value=Array(shape=(84, 10), dtype=float32)\n",
       "    ),\n",
       "    bias=Param(\n",
       "      value=Array(shape=(10,), dtype=float32)\n",
       "    ),\n",
       "    in_features=84,\n",
       "    out_features=10,\n",
       "    use_bias=True,\n",
       "    dtype=None,\n",
       "    param_dtype=<class 'jax.numpy.float32'>,\n",
       "    precision=None,\n",
       "    kernel_init=<function variance_scaling.<locals>.init at 0x1680a4cc0>,\n",
       "    bias_init=<function zeros at 0x12f47d300>,\n",
       "    dot_general=<function dot_general at 0x11f6afc40>\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f4ab4e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[-0.28011444,  0.2215457 ,  0.51564384, -0.6677027 ,  0.5182838 ,\n",
       "        -0.511331  , -0.6132752 ,  0.76808715,  0.6332212 ,  0.18320563]],      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = jnp.ones((1, 28, 28, 1))\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdc2dcc",
   "metadata": {
    "origin_pos": 17
   },
   "source": [
    "## Training\n",
    "\n",
    "Now that we have implemented the model,\n",
    "let's [**run an experiment to see how the LeNet-5 model fares on Fashion-MNIST**].\n",
    "\n",
    "While CNNs have fewer parameters,\n",
    "they can still be more expensive to compute\n",
    "than similarly deep MLPs\n",
    "because each parameter participates in many more\n",
    "multiplications.\n",
    "If you have access to a GPU, this might be a good time\n",
    "to put it into action to speed up training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0aac3e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ce10196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24f67fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255.\n",
    "# added channel axis\n",
    "x_train = x_train[..., np.newaxis]\n",
    "y_train = y_train.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "687b32f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9633fc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b7ff071",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 10\n",
    "batch_size = 256\n",
    "train_data = train_data.repeat(n_epoch).shuffle(buffer_size=batch_size)\n",
    "train_data = train_data.batch(batch_size, drop_remainder=True).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca958f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2343"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.cardinality().numpy() # (60000 * n_epoch) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d421b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test / 255.\n",
    "x_test = x_test[..., np.newaxis]\n",
    "y_test = y_test.astype(np.int32)\n",
    "test_data = tf.data.Dataset.from_tensor_slices((x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e089604a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.shuffle(batch_size) \n",
    "test_data = test_data.batch(batch_size, drop_remainder=True).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "734e43b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(model, batch):\n",
    "  x, y = batch\n",
    "  logits = model(x)\n",
    "  loss = optax.softmax_cross_entropy_with_integer_labels(logits=logits, labels=y).mean()\n",
    "  return loss, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b900f532",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = nnx.Optimizer(model, optax.adam(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b74fe30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = nnx.MultiMetric(\n",
    "  accuracy=nnx.metrics.Accuracy(),\n",
    "  loss=nnx.metrics.Average('loss'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "30f4243a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.jit\n",
    "def train_step(model, optimizer: nnx.Optimizer, metrics: nnx.MultiMetric, batch):\n",
    "  \"\"\"Train for a single step.\"\"\"\n",
    "  grad_fn = nnx.value_and_grad(loss_fn, has_aux=True)\n",
    "  (loss, logits), grads = grad_fn(model, batch)\n",
    "  metrics.update(loss=loss, logits=logits, labels=batch[1])\n",
    "  optimizer.update(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "154c9eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.jit\n",
    "def eval_step(model, metrics: nnx.MultiMetric, batch):\n",
    "  loss, logits = loss_fn(model, batch)\n",
    "  metrics.update(loss=loss, logits=logits, labels=batch[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2eea7cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-24 13:57:52.361340: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-10-24 13:57:59.027785: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-10-24 13:58:05.671240: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-10-24 13:58:12.320985: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-10-24 13:58:18.999153: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-10-24 13:58:25.822800: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-10-24 13:58:32.644561: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-10-24 13:58:39.208668: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-10-24 13:58:45.780661: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-10-24 13:58:48.043360: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "eval_every = 250\n",
    "\n",
    "metrics_history = {\n",
    "  'train_loss': [],\n",
    "  'train_accuracy': [],\n",
    "  'test_loss': [],\n",
    "  'test_accuracy': [],\n",
    "}\n",
    "\n",
    "for step, batch in enumerate(train_data.as_numpy_iterator()):\n",
    "  train_step(model, optimizer, metrics, batch)\n",
    "  \n",
    "  if step > 0 and (step % eval_every == 0): \n",
    "    for metric, value in metrics.compute().items():\n",
    "      metrics_history[f'train_{metric}'].append(value)\n",
    "    metrics.reset()\n",
    "\n",
    "    for test_batch in test_data.as_numpy_iterator():\n",
    "      eval_step(model, metrics, test_batch)\n",
    "\n",
    "    for metric, value in metrics.compute().items():\n",
    "      metrics_history[f'test_{metric}'].append(value)\n",
    "    metrics.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9b462b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "ax1.set_title('Loss')\n",
    "ax2.set_title('Accuracy')\n",
    "for dataset in ('train', 'test'):\n",
    "  ax1.plot(metrics_history[f'{dataset}_loss'], label=f'{dataset}_loss')\n",
    "  ax2.plot(metrics_history[f'{dataset}_accuracy'], label=f'{dataset}_accuracy')\n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "required_libs": []
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
