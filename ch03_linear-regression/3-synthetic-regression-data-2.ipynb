{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da466415",
   "metadata": {
    "origin_pos": 1
   },
   "source": [
    "# Synthetic Regression Data\n",
    ":label:`sec_synthetic-regression-data`\n",
    "\n",
    "\n",
    "Machine learning is all about extracting information from data.\n",
    "So you might wonder, what could we possibly learn from synthetic data?\n",
    "While we might not care intrinsically about the patterns \n",
    "that we ourselves baked into an artificial data generating model,\n",
    "such datasets are nevertheless useful for didactic purposes,\n",
    "helping us to evaluate the properties of our learning \n",
    "algorithms and to confirm that our implementations work as expected.\n",
    "For example, if we create data for which the correct parameters are known *a priori*,\n",
    "then we can check that our model can in fact recover them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df944117",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:45:17.649818Z",
     "iopub.status.busy": "2023-08-18T19:45:17.649232Z",
     "iopub.status.idle": "2023-08-18T19:45:24.579903Z",
     "shell.execute_reply": "2023-08-18T19:45:24.579031Z"
    },
    "origin_pos": 5,
    "tab": [
     "jax"
    ]
   },
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import tensorflow as tf\n",
    "from tensorflow_probability.substrates import jax as tfp\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89bfd5a",
   "metadata": {
    "origin_pos": 6
   },
   "source": [
    "## Generating the Dataset\n",
    "\n",
    "For this example, we will work in low dimension\n",
    "for succinctness.\n",
    "The following code snippet generates 1000 examples\n",
    "with 2-dimensional features drawn \n",
    "from a standard normal distribution.\n",
    "The resulting design matrix $\\mathbf{X}$\n",
    "belongs to $\\mathbb{R}^{1000 \\times 2}$. \n",
    "We generate each label by applying \n",
    "a *ground truth* linear function, \n",
    "corrupting them via additive noise $\\boldsymbol{\\epsilon}$, \n",
    "drawn independently and identically for each example:\n",
    "\n",
    "(**$$\\mathbf{y}= \\mathbf{X} \\mathbf{w} + b + \\boldsymbol{\\epsilon}.$$**)\n",
    "\n",
    "For convenience we assume that $\\boldsymbol{\\epsilon}$ is drawn \n",
    "from a normal distribution with mean $\\mu= 0$ \n",
    "and standard deviation $\\sigma = 0.01$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8178cfe1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:45:24.583913Z",
     "iopub.status.busy": "2023-08-18T19:45:24.583065Z",
     "iopub.status.idle": "2023-08-18T19:45:24.589466Z",
     "shell.execute_reply": "2023-08-18T19:45:24.588668Z"
    },
    "origin_pos": 7,
    "tab": [
     "jax"
    ]
   },
   "outputs": [],
   "source": [
    "# generate synthetic regression data\n",
    "def gen_reg_data(w, b, seed, noise=0.01, n=1000):\n",
    "\tkey = tfp.util.SeedStream(seed, salt=\"gen_reg_data\")\n",
    "\tnormal = tfd.Normal(loc=0.0, scale=1.0)\n",
    "\tX = normal.sample((n, w.shape[0]), seed=key())\n",
    "\tnoise = normal.sample((n, 1), seed=key()) * noise\n",
    "\treturn X, jnp.matmul(X, jnp.reshape(w, (-1, 1))) + b + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c622be",
   "metadata": {
    "origin_pos": 8
   },
   "source": [
    "Below, we set the true parameters to $\\mathbf{w} = [2, -3.4]^\\top$ and $b = 4.2$.\n",
    "Later, we can check our estimated parameters against these *ground truth* values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5987e3a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:45:24.592617Z",
     "iopub.status.busy": "2023-08-18T19:45:24.592101Z",
     "iopub.status.idle": "2023-08-18T19:45:25.254263Z",
     "shell.execute_reply": "2023-08-18T19:45:25.253332Z"
    },
    "origin_pos": 9,
    "tab": [
     "jax"
    ]
   },
   "outputs": [],
   "source": [
    "data = gen_reg_data(w=jnp.array([2, 3.4]), b=4.2, seed=714)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595a0e1c",
   "metadata": {
    "origin_pos": 10
   },
   "source": [
    "[**Each row in `features` consists of a vector in $\\mathbb{R}^2$ and each row in `labels` is a scalar.**] Let's have a look at the first entry.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b0c300a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:45:25.258057Z",
     "iopub.status.busy": "2023-08-18T19:45:25.257483Z",
     "iopub.status.idle": "2023-08-18T19:45:25.355333Z",
     "shell.execute_reply": "2023-08-18T19:45:25.354471Z"
    },
    "origin_pos": 11,
    "tab": [
     "jax"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: [ 1.5143707 -1.1325673] \n",
      "label: [3.3820975]\n"
     ]
    }
   ],
   "source": [
    "print('features:', data[0][0],'\\nlabel:', data[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba0bc45",
   "metadata": {
    "origin_pos": 12
   },
   "source": [
    "## Reading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "770b0cf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:45:25.359355Z",
     "iopub.status.busy": "2023-08-18T19:45:25.358658Z",
     "iopub.status.idle": "2023-08-18T19:45:25.364123Z",
     "shell.execute_reply": "2023-08-18T19:45:25.363312Z"
    },
    "origin_pos": 13,
    "tab": [
     "jax"
    ]
   },
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices(data).repeat().shuffle(100)\n",
    "train_data = train_data.batch(50, drop_remainder=True).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bba3d5",
   "metadata": {
    "origin_pos": 14
   },
   "source": [
    "To build some intuition, let's inspect the first minibatch of\n",
    "data. Each minibatch of features provides us with both its size and the dimensionality of input features.\n",
    "Likewise, our minibatch of labels will have a matching shape given by `batch_size`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ee41078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (50, 2) \n",
      "y shape: (50, 1)\n"
     ]
    }
   ],
   "source": [
    "X, y = next(iter(train_data))\n",
    "print('X shape:', X.shape, '\\ny shape:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661e0816",
   "metadata": {
    "origin_pos": 24
   },
   "source": [
    "## Summary\n",
    "\n",
    "Data loaders are a convenient way of abstracting out \n",
    "the process of loading and manipulating data. \n",
    "This way the same machine learning *algorithm* \n",
    "is capable of processing many different types and sources of data \n",
    "without the need for modification. \n",
    "One of the nice things about data loaders \n",
    "is that they can be composed. \n",
    "For instance, we might be loading images \n",
    "and then have a postprocessing filter \n",
    "that crops them or modifies them in other ways. \n",
    "As such, data loaders can be used \n",
    "to describe an entire data processing pipeline. \n",
    "\n",
    "As for the model itself, the two-dimensional linear model \n",
    "is about the simplest we might encounter. \n",
    "It lets us test out the accuracy of regression models \n",
    "without worrying about having insufficient amounts of data \n",
    "or an underdetermined system of equations. \n",
    "We will put this to good use in the next section.  \n",
    "\n",
    "\n",
    "## Exercises\n",
    "\n",
    "1. What will happen if the number of examples cannot be divided by the batch size. How would you change this behavior by specifying a different argument by using the framework's API?\n",
    "1. Suppose that we want to generate a huge dataset, where both the size of the parameter vector `w` and the number of examples `num_examples` are large.\n",
    "    1. What happens if we cannot hold all data in memory?\n",
    "    1. How would you shuffle the data if it is held on disk? Your task is to design an *efficient* algorithm that does not require too many random reads or writes. Hint: [pseudorandom permutation generators](https://en.wikipedia.org/wiki/Pseudorandom_permutation) allow you to design a reshuffle without the need to store the permutation table explicitly :cite:`Naor.Reingold.1999`. \n",
    "1. Implement a data generator that produces new data on the fly, every time the iterator is called. \n",
    "1. How would you design a random data generator that generates *the same* data each time it is called?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f0bb25",
   "metadata": {
    "origin_pos": 28,
    "tab": [
     "jax"
    ]
   },
   "source": [
    "[Discussions](https://discuss.d2l.ai/t/17975)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "required_libs": []
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
