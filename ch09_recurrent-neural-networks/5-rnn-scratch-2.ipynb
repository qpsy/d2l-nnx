{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb585066",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# Recurrent Neural Network Implementation from Scratch\n",
    ":label:`sec_rnn-scratch`\n",
    "\n",
    "We are now ready to implement an RNN from scratch.\n",
    "In particular, we will train this RNN to function\n",
    "as a character-level language model\n",
    "(see :numref:`sec_rnn`)\n",
    "and train it on a corpus consisting of \n",
    "the entire text of H. G. Wells' *The Time Machine*,\n",
    "following the data processing steps \n",
    "outlined in :numref:`sec_text-sequence`.\n",
    "We start by loading the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4dce1c2",
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "5"
    },
    "execution": {
     "iopub.execute_input": "2023-08-18T19:28:20.061373Z",
     "iopub.status.busy": "2023-08-18T19:28:20.060611Z",
     "iopub.status.idle": "2023-08-18T19:28:27.289832Z",
     "shell.execute_reply": "2023-08-18T19:28:27.288912Z"
    },
    "origin_pos": 5,
    "tab": [
     "jax"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "from flax import nnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a633f5",
   "metadata": {
    "origin_pos": 6
   },
   "source": [
    "## RNN Model\n",
    "\n",
    "We begin by defining a class \n",
    "to implement the RNN model\n",
    "(:numref:`subsec_rnn_w_hidden_states`).\n",
    "Note that the number of hidden units `num_hiddens` \n",
    "is a tunable hyperparameter.\n",
    "\n",
    "[**The `forward` method below defines how to compute \n",
    "the output and hidden state at any time step,\n",
    "given the current input and the state of the model\n",
    "at the previous time step.**]\n",
    "Note that the RNN model loops through \n",
    "the outermost dimension of `inputs`,\n",
    "updating the hidden state \n",
    "one time step at a time.\n",
    "The model here uses a $\\tanh$ activation function (:numref:`subsec_tanh`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb70e996",
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "7"
    },
    "execution": {
     "iopub.execute_input": "2023-08-18T19:28:27.295154Z",
     "iopub.status.busy": "2023-08-18T19:28:27.293636Z",
     "iopub.status.idle": "2023-08-18T19:28:27.301018Z",
     "shell.execute_reply": "2023-08-18T19:28:27.300003Z"
    },
    "origin_pos": 8,
    "tab": [
     "jax"
    ]
   },
   "outputs": [],
   "source": [
    "class RNNScratch(nnx.Module): \n",
    "\t\"\"\"The RNN model implemented from scratch.\"\"\"\n",
    "\tdef __init__(self, num_inputs: int, num_hiddens: int, rngs: nnx.Rngs):\n",
    "\t\tself.W_xh = nnx.Param(nnx.initializers.he_normal()(rngs(), (num_inputs, num_hiddens)))\n",
    "\t\tself.W_hh = nnx.Param(nnx.initializers.he_normal()(rngs(), (num_hiddens, num_hiddens)))\n",
    "\t\tself.b_h = nnx.Param(nnx.initializers.zeros_init()(rngs(), (num_hiddens,)))\n",
    "\t\tself.num_hiddens = num_hiddens\n",
    "\n",
    "\tdef __call__(self, inputs, state=None):\n",
    "\t\tif state is not None:\n",
    "\t\t\tstate, = state\n",
    "\t\toutputs = []\n",
    "\t\tfor X in inputs:  # Shape of inputs: (num_steps, batch_size, num_inputs)\n",
    "\t\t\tstate = jnp.tanh(jnp.matmul(X, self.W_xh) + (\n",
    "\t\t\t\tjnp.matmul(state, self.W_hh) if state is not None else 0)\n",
    "\t\t\t\t\t\t\t\t\t\t\t+ self.b_h)\n",
    "\t\t\toutputs.append(state)\n",
    "\t\treturn outputs, state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e72875",
   "metadata": {
    "origin_pos": 12
   },
   "source": [
    "We can feed a minibatch of input sequences into an RNN model as follows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78fdec82",
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "11"
    },
    "execution": {
     "iopub.execute_input": "2023-08-18T19:28:27.312729Z",
     "iopub.status.busy": "2023-08-18T19:28:27.312221Z",
     "iopub.status.idle": "2023-08-18T19:28:29.256728Z",
     "shell.execute_reply": "2023-08-18T19:28:29.255776Z"
    },
    "origin_pos": 14,
    "tab": [
     "jax"
    ]
   },
   "outputs": [],
   "source": [
    "# batch_size, num_inputs, num_hiddens, num_steps = 2, 16, 32, 100\n",
    "batch_size, num_inputs, num_hiddens, num_steps = 2, 2, 3, 2\n",
    "rnn = RNNScratch(num_inputs, num_hiddens, rngs=nnx.Rngs(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3fd2d1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = jnp.ones((num_steps, batch_size, num_inputs))\n",
    "outputs, state = rnn(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5be20f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Array([[ 0.9977814, -0.7699115,  0.8565357],\n",
       "        [ 0.9977814, -0.7699115,  0.8565357]], dtype=float32),\n",
       " Array([[ 0.9995162 , -0.9408712 ,  0.42814836],\n",
       "        [ 0.9995162 , -0.9408712 ,  0.42814836]], dtype=float32)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e5b66bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 0.9995162 , -0.9408712 ,  0.42814836],\n",
       "       [ 0.9995162 , -0.9408712 ,  0.42814836]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0a735a",
   "metadata": {
    "origin_pos": 15
   },
   "source": [
    "Let's check whether the RNN model\n",
    "produces results of the correct shapes\n",
    "to ensure that the dimensionality \n",
    "of the hidden state remains unchanged.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48058338",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:28:29.260931Z",
     "iopub.status.busy": "2023-08-18T19:28:29.260359Z",
     "iopub.status.idle": "2023-08-18T19:28:29.265873Z",
     "shell.execute_reply": "2023-08-18T19:28:29.264852Z"
    },
    "origin_pos": 16,
    "tab": [
     "jax"
    ]
   },
   "outputs": [],
   "source": [
    "def check_len(a, n):  #@save\n",
    "    \"\"\"Check the length of a list.\"\"\"\n",
    "    assert len(a) == n, f'list\\'s length {len(a)} != expected length {n}'\n",
    "\n",
    "def check_shape(a, shape):  #@save\n",
    "    \"\"\"Check the shape of a tensor.\"\"\"\n",
    "    assert a.shape == shape, \\\n",
    "            f'tensor\\'s shape {a.shape} != expected shape {shape}'\n",
    "\n",
    "check_len(outputs, num_steps)\n",
    "check_shape(outputs[0], (batch_size, num_hiddens))\n",
    "check_shape(state, (batch_size, num_hiddens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df15190",
   "metadata": {
    "origin_pos": 17
   },
   "source": [
    "## RNN-Based Language Model\n",
    "\n",
    "The following `RNNLMScratch` class defines \n",
    "an RNN-based language model,\n",
    "where we pass in our RNN \n",
    "via the `rnn` argument\n",
    "of the `__init__` method.\n",
    "When training language models, \n",
    "the inputs and outputs are \n",
    "from the same vocabulary. \n",
    "Hence, they have the same dimension,\n",
    "which is equal to the vocabulary size.\n",
    "Note that we use perplexity to evaluate the model. \n",
    "As discussed in :numref:`subsec_perplexity`, this ensures \n",
    "that sequences of different length are comparable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ecd134",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNLMScratch(nnx.Module):  #@save\n",
    "\t\"\"\"The RNN-based language model implemented from scratch.\"\"\"\n",
    "\n",
    "\tdef __init__(self, rnn: nnx.Module, vocab_size: int, rngs: nnx.Rngs):\n",
    "\t\tself.W_hq = nnx.Param(nnx.initializers.he_normal()(rngs(), (rnn.num_hiddens, vocab_size)))\n",
    "\t\tself.b_q = nnx.Param(nnx.initializers.zeros_init()(rngs(), (vocab_size,)))\n",
    "\t\tself.vocab_size = vocab_size\n",
    "\t\n",
    "\tdef one_hot(self, X):\n",
    "    # Output shape: (num_steps, batch_size, vocab_size)\n",
    "\t\treturn jax.nn.one_hot(X.T, self.vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc88df9",
   "metadata": {
    "origin_pos": 21
   },
   "source": [
    "### [**One-Hot Encoding**]\n",
    "\n",
    "Recall that each token is represented \n",
    "by a numerical index indicating the\n",
    "position in the vocabulary of the \n",
    "corresponding word/character/word piece.\n",
    "You might be tempted to build a neural network\n",
    "with a single input node (at each time step),\n",
    "where the index could be fed in as a scalar value.\n",
    "This works when we are dealing with numerical inputs \n",
    "like price or temperature, where any two values\n",
    "sufficiently close together\n",
    "should be treated similarly.\n",
    "But this does not quite make sense. \n",
    "The $45^{\\textrm{th}}$ and $46^{\\textrm{th}}$ words \n",
    "in our vocabulary happen to be \"their\" and \"said\",\n",
    "whose meanings are not remotely similar.\n",
    "\n",
    "When dealing with such categorical data,\n",
    "the most common strategy is to represent\n",
    "each item by a *one-hot encoding*\n",
    "(recall from :numref:`subsec_classification-problem`).\n",
    "A one-hot encoding is a vector whose length\n",
    "is given by the size of the vocabulary $N$,\n",
    "where all entries are set to $0$,\n",
    "except for the entry corresponding \n",
    "to our token, which is set to $1$.\n",
    "For example, if the vocabulary had five elements,\n",
    "then the one-hot vectors corresponding \n",
    "to indices 0 and 2 would be the following.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c7040fb2",
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "18"
    },
    "execution": {
     "iopub.execute_input": "2023-08-18T19:28:29.280049Z",
     "iopub.status.busy": "2023-08-18T19:28:29.279473Z",
     "iopub.status.idle": "2023-08-18T19:28:29.367702Z",
     "shell.execute_reply": "2023-08-18T19:28:29.366569Z"
    },
    "origin_pos": 25,
    "tab": [
     "jax"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.nn.one_hot(jnp.array([0, 2]), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dfc26b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nnx.one_hot(jnp.array([0, 2]), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83fcc41",
   "metadata": {
    "origin_pos": 26
   },
   "source": [
    "(**The minibatches that we sample at each iteration\n",
    "will take the shape (batch size, number of time steps).\n",
    "Once representing each input as a one-hot vector,\n",
    "we can think of each minibatch as a three-dimensional tensor, \n",
    "where the length along the third axis \n",
    "is given by the vocabulary size (`len(vocab)`).**)\n",
    "We often transpose the input so that we will obtain an output \n",
    "of shape (number of time steps, batch size, vocabulary size).\n",
    "This will allow us to loop more conveniently through the outermost dimension\n",
    "for updating hidden states of a minibatch,\n",
    "time step by time step\n",
    "(e.g., in the above `forward` method).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae05291",
   "metadata": {},
   "source": [
    "### I'll be back."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "required_libs": []
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
